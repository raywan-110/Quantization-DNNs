{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、 PTQ\r\n",
    "$$\r\n",
    "r = S(q-Z)\\\\\r\n",
    "S = \\frac{r_{max}-r_{rmin}}{q_{max}-q_{min}} \\\\ \\\\\r\n",
    "\r\n",
    "Z = round(q_{max}-\\frac{r_{max}}{S})\r\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. core formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "from torchvision import datasets, transforms\r\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcScaleZeroPoint(rmin, rmax, num_bits=8, signed=False):\r\n",
    "    '''calculate S, Z parameters for certain range real numbers'''\r\n",
    "    if signed:\r\n",
    "        qmin = - 2. **(num_bits - 1)\r\n",
    "        qmax = 2. **(num_bits - 1) - 1\r\n",
    "    else:\r\n",
    "        qmin = 0.\r\n",
    "        qmax = 2. **(num_bits - 1)\r\n",
    "    scale = float((rmax - rmin)/(qmax - qmin))\r\n",
    "    zero_point = qmax - rmax / scale\r\n",
    "    # handle overflow\r\n",
    "    if zero_point < qmin:\r\n",
    "        zero_point = qmin\r\n",
    "    if zero_point > qmax:\r\n",
    "        zero_point = qmax\r\n",
    "    zero_point = int(zero_point)\r\n",
    "    return scale, zero_point\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.015625, 64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmax = 1\r\n",
    "rmin = -1\r\n",
    "scale, zero_point = calcScaleZeroPoint(rmin,rmax,num_bits=8,signed=False)\r\n",
    "scale, zero_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quantizer for tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_tensor(x, scale, zero_point, num_bits=8, signed=False):\r\n",
    "    '''input: x, real value tensor\r\n",
    "       output: q_x, quantized value tensor'''\r\n",
    "    if signed:\r\n",
    "        qmin = - 2. **(num_bits - 1)\r\n",
    "        qmax = 2. **(num_bits - 1) - 1\r\n",
    "    else:\r\n",
    "        qmin = 0.\r\n",
    "        qmax = 2. **(num_bits - 1)\r\n",
    "    q_x = x / scale + zero_point\r\n",
    "    q_x.clamp_(qmin, qmax).round_()\r\n",
    "    if signed:\r\n",
    "        return q_x.char()\r\n",
    "    else:\r\n",
    "        return q_x.byte() # convert to int32\r\n",
    "def dequantize_tensor(q,scale,zero_point):\r\n",
    "    r = scale*(q - zero_point)\r\n",
    "    return r.float()\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7974, -0.6490, -2.2510],\n",
      "        [-1.3110, -0.8741, -1.9719]])\n",
      "tensor(0.7974)\n",
      "tensor(-2.2510)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,3,dtype=torch.float)\r\n",
    "rmax = a.max()\r\n",
    "rmin = a.min()\r\n",
    "print(a)\r\n",
    "print(rmax)\r\n",
    "print(rmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02381531521677971\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "scale, zero_point = calcScaleZeroPoint(rmin,rmax)\r\n",
    "print(scale)\r\n",
    "print(zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin value: \n",
      "tensor([[ 0.7974, -0.6490, -2.2510],\n",
      "        [-1.3110, -0.8741, -1.9719]])\n",
      "quantized value: \n",
      "tensor([[127,  67,   0],\n",
      "        [ 39,  57,  11]], dtype=torch.uint8)\n",
      "dequantized value: \n",
      "tensor([[0.7859, 5.4537, 3.8581],\n",
      "        [4.7869, 5.2156, 4.1200]])\n"
     ]
    }
   ],
   "source": [
    "q_a = quantize_tensor(a,scale,zero_point,signed=False)\r\n",
    "print('origin value: ')\r\n",
    "print(a)\r\n",
    "print('quantized value: ')\r\n",
    "print(q_a)\r\n",
    "print('dequantized value: ')\r\n",
    "print(dequantize_tensor(q_a,scale,zero_point))\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. package as a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qparam:\r\n",
    "    def __init__(self, num_bits=8):\r\n",
    "        self.num_bits = num_bits\r\n",
    "        self.scale = None\r\n",
    "        self.zero_point = None\r\n",
    "        self.rmin = None\r\n",
    "        self.rmax = None\r\n",
    "    \r\n",
    "    def calcScaleZeroPoint(self, rmin, rmax, num_bits=8, signed=False):\r\n",
    "        '''calculate S, Z parameters for certain range real numbers'''\r\n",
    "        if signed:\r\n",
    "            qmin = - 2. **(num_bits - 1)\r\n",
    "            qmax = 2. **(num_bits - 1) - 1\r\n",
    "        else:\r\n",
    "            qmin = 0.\r\n",
    "            qmax = 2. **(num_bits - 1)\r\n",
    "        scale = float((rmax - rmin)/(qmax - qmin))\r\n",
    "        zero_point = qmax - rmax / scale\r\n",
    "        # handle overflow( have been handled in Qparam)\r\n",
    "        # if zero_point < qmin:\r\n",
    "        #     zero_point = qmin\r\n",
    "        # if zero_point > qmax:\r\n",
    "        #     zero_point = qmax\r\n",
    "\r\n",
    "        zero_point = int(zero_point)\r\n",
    "        return scale, zero_point\r\n",
    "\r\n",
    "    def update(self, tensor):\r\n",
    "        '''update all the params via input tensor'''\r\n",
    "        if self.rmax is None or self.rmax < tensor.max():\r\n",
    "            self.rmax = tensor.max()\r\n",
    "        self.rmax = 0 if self.rmax < 0 else self.rmax # guarantee that zero_point won't overflow\r\n",
    "        if self.rmin is None or self.rmin > tensor.min():\r\n",
    "            self.rmin = tensor.min()\r\n",
    "        self.rmin = 0 if self.rmin > 0 else self.rmin\r\n",
    "        \r\n",
    "        self.scale, self.zero_point = self.calcScaleZeroPoint(self.rmin,self.rmax,self.num_bits)\r\n",
    "    \r\n",
    "    def quantize_tensor(self, x, signed=False):\r\n",
    "        '''input: x, real value tensor\r\n",
    "           output: q_x, quantized value tensor'''\r\n",
    "        if signed:\r\n",
    "            qmin = - 2. **(self.num_bits - 1)\r\n",
    "            qmax = 2. **(self.num_bits - 1) - 1\r\n",
    "        else:\r\n",
    "            qmin = 0.\r\n",
    "            qmax = 2. **(self.num_bits - 1)\r\n",
    "        q_x = x / self.scale + self.zero_point\r\n",
    "        q_x.clamp_(qmin, qmax).round_()\r\n",
    "        if signed:\r\n",
    "            return q_x.char()\r\n",
    "        else:\r\n",
    "            return q_x.byte() # convert to int32\r\n",
    "    \r\n",
    "    def dequantize_tensor(self, q):\r\n",
    "        r = self.scale*(q - self.zero_point)\r\n",
    "        return r.float()\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. QNet base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QModule(nn.Module):\r\n",
    "    def __init__(self, qi=True, qo=True, num_bits=8):\r\n",
    "        super().__init__()\r\n",
    "        if qi:\r\n",
    "            self.qi = Qparam(num_bits) # quantizer for input tensor\r\n",
    "        if qo:\r\n",
    "            self.qo = Qparam(num_bits) # quantizer for output tensor\r\n",
    "    \r\n",
    "    def freeze(self):\r\n",
    "        '''freeze params of the network'''\r\n",
    "        pass\r\n",
    "\r\n",
    "    def quantize_inference(self, x):\r\n",
    "        raise NotImplementedError('quantize_inference must be implemented.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implement important QNet component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QConv2d(QModule):\r\n",
    "\r\n",
    "    def __init__(self, conv_module, qi=True, qo=True, num_bits=8):\r\n",
    "        super(QConv2d,self).__init__(qi=qi, qo=qo, num_bits=num_bits) # quantizer for input output\r\n",
    "        self.num_bits = num_bits\r\n",
    "        self.conv_module = conv_module\r\n",
    "        self.qw = Qparam(num_bits) # quantizer for weights\r\n",
    "\r\n",
    "    def freeze(self,qi=None, qo=None):\r\n",
    "        '''some hidden module may not need to calculate rmin/rmax but reuse former\r\n",
    "        qo as its own qi. for conv2d layer, it has its own qi qo'''\r\n",
    "\r\n",
    "        if hasattr(self, 'qi') and qi is not None:\r\n",
    "            raise ValueError('qi has been provided in init function.')\r\n",
    "        if not hasattr(self, 'qi') and qi is None:\r\n",
    "            raise ValueError('qi is not existed, should be provided.')\r\n",
    "\r\n",
    "        if hasattr(self, 'qo') and qo is not None:\r\n",
    "            raise ValueError('qo has been provided in init function.')\r\n",
    "        if not hasattr(self, 'qo') and qo is None:\r\n",
    "            raise ValueError('qo is not existed, should be provided.')\r\n",
    "        \r\n",
    "        if qi is not None:\r\n",
    "            self.qi = qi\r\n",
    "        if qo is not None:\r\n",
    "            self.qo = qo\r\n",
    "        \r\n",
    "        # TODO implement it by bit shift\r\n",
    "        self.M = self.qw.scale * self.qi.scale / self.qo.scale # actually, it should be implement by bit shift\r\n",
    "        self.conv_module.weight.data = self.qw.quantize_tensor(self.conv_module.weight.data)\r\n",
    "        # TODO expand the product\r\n",
    "        self.conv_module.weight.data = self.conv_module.weight.data - self.qw.zero_point\r\n",
    "\r\n",
    "        self.conv_module.bias.data = quantize_tensor(self.conv_module.bias.data,self.qw.scale * self.qi.scale, zero_point=0,signed=True) # since Z = 0, r=Sq, the value range of q must contain negative numbers\r\n",
    "\r\n",
    "    # used in QAT\r\n",
    "    def forward(self,x):\r\n",
    "        # statistics and update\r\n",
    "        if hasattr(self, 'qi'):\r\n",
    "            self.qi.update(x)\r\n",
    "            # simulate quantization effects of input\r\n",
    "            x = self.qi.quantize_tensor(x)\r\n",
    "            x = self.qi.dequantize_tensor(x)\r\n",
    "        self.qw.update(self.conv_module.weight.data)\r\n",
    "        # simulate quantization effects\r\n",
    "        self.conv_module.weight.data = self.qw.quantize_tensor(self.conv_module.weight.data)\r\n",
    "        self.conv_module.weight.data = self.qw.dequantize_tensor(self.conv_module.weight.data)\r\n",
    "\r\n",
    "        x = self.conv_module(x)\r\n",
    "        \r\n",
    "        # qo's params maybe useful for latter layers\r\n",
    "        if hasattr(self,'qo'):\r\n",
    "            self.qo.update(x)\r\n",
    "        \r\n",
    "        return x\r\n",
    "\r\n",
    "    def quantize_inference(self, x):\r\n",
    "        # use original formula to calculate\r\n",
    "        x = x - self.qi.zero_point\r\n",
    "        # calculate in 8 bits integer\r\n",
    "        x = self.conv_module(x)\r\n",
    "        x = (self.M * x).round().int() # self.M is still in float format, need to be concert to int\r\n",
    "        x = x +  self.qo.zero_point\r\n",
    "        return x\r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLinear(QModule):\r\n",
    "\r\n",
    "    def __init__(self, fc_module, qi, qo, num_bits=8):\r\n",
    "        super().__init__(qi=qi, qo=qo, num_bits=num_bits)\r\n",
    "        self.num_bits = num_bits\r\n",
    "        self.fc_module = fc_module\r\n",
    "        self.qw = Qparam(num_bits)\r\n",
    "\r\n",
    "    def freeze(self,qi=None, qo=None):\r\n",
    "        '''some hidden module may not need to calculate rmin/rmax but reuse former\r\n",
    "        qo as its own qi. for conv2d layer, it has its own qi qo'''\r\n",
    "\r\n",
    "        if hasattr(self, 'qi') and qi is not None:\r\n",
    "            raise ValueError('qi has been provided in init function.')\r\n",
    "        if not hasattr(self, 'qi') and qi is None:\r\n",
    "            raise ValueError('qi is not existed, should be provided.')\r\n",
    "\r\n",
    "        if hasattr(self, 'qo') and qo is not None:\r\n",
    "            raise ValueError('qo has been provided in init function.')\r\n",
    "        if not hasattr(self, 'qo') and qo is None:\r\n",
    "            raise ValueError('qo is not existed, should be provided.')\r\n",
    "        \r\n",
    "        if qi is not None:\r\n",
    "            self.qi = qi\r\n",
    "        if qo is not None:\r\n",
    "            self.qo = qo\r\n",
    "        \r\n",
    "        # TODO implement it by bit shift\r\n",
    "        self.M = self.qw.scale * self.qi.scale / self.qo.scale # actually, it should be implement by bit shift\r\n",
    "        self.fc_module.weight.data = self.qw.quantize_tensor(self.fc_module.weight.data)\r\n",
    "        # TODO expand the product\r\n",
    "        self.fc_module.weight.data = self.fc_module.weight.data - self.qw.zero_point\r\n",
    "\r\n",
    "        self.fc_module.bias.data = quantize_tensor(self.fc_module.bias.data,self.qw.scale * self.qi.scale, zero_point=0,signed=True) # since Z = 0, r=Sq, the value range of q must contain negative numbers\r\n",
    "\r\n",
    "    # used in QAT\r\n",
    "    def forward(self,x):\r\n",
    "        # statistics and update\r\n",
    "        if hasattr(self, 'qi'):\r\n",
    "            self.qi.update(x)\r\n",
    "            # simulate quantization effects of input\r\n",
    "            x = self.qi.quantize_tensor(x)\r\n",
    "            x = self.qi.deuantize_tensor(x)\r\n",
    "        self.qw.update(self.fc_module.weight.data)\r\n",
    "        # simulate quantization effects\r\n",
    "        self.fc_module.weight.data = self.qw.quantize_tensor(self.fc_module.weight.data)\r\n",
    "        self.fc_module.weight.data = self.qw.dequantize_tensor(self.fc_module.weight.data)\r\n",
    "\r\n",
    "        x = self.fc_module(x) # no need to quantize bias \r\n",
    "        \r\n",
    "        # qo's params maybe useful for latter layers\r\n",
    "        if hasattr(self,'qo'):\r\n",
    "            self.qo.update(x)\r\n",
    "        \r\n",
    "        return x\r\n",
    "\r\n",
    "    def quantize_inference(self, x):\r\n",
    "        # use original formula to calculate\r\n",
    "        x = x - self.qi.zero_point\r\n",
    "        # calculate in integer\r\n",
    "        x = self.fc_module(x)\r\n",
    "        x = (self.M * x).round().int()\r\n",
    "        x = x + self.qo.zero_point\r\n",
    "        return x\r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QReLU(QModule):\r\n",
    "\r\n",
    "    def __init__(self, relu_module, qi=False, num_bits=None):\r\n",
    "        super(QReLU, self).__init__(qi=qi, num_bits=num_bits)\r\n",
    "        self.relu_module = relu_module\r\n",
    "\r\n",
    "    def freeze(self, qi=None):\r\n",
    "        \r\n",
    "        if hasattr(self, 'qi') and qi is not None:\r\n",
    "            raise ValueError('qi has been provided in init function.')\r\n",
    "        if not hasattr(self, 'qi') and qi is None:\r\n",
    "            raise ValueError('qi is not existed, should be provided.')\r\n",
    "\r\n",
    "        if qi is not None:\r\n",
    "            self.qi = qi # relu module reuse former layers' qo\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        if hasattr(self, 'qi'):\r\n",
    "            self.qi.update(x)\r\n",
    "            x = self.qi.quantize_tensor(x)\r\n",
    "            x = self.qi.dequantize_tensor(x)\r\n",
    "        \r\n",
    "        x = self.relu_module(x)\r\n",
    "\r\n",
    "        return x\r\n",
    "    \r\n",
    "    def quantize_inference(self, x):\r\n",
    "       x = x.clone()\r\n",
    "       x[x < self.qi.zero_point] = self.qi.zero_point\r\n",
    "       return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QMaxPooling2d(QModule):\r\n",
    "\r\n",
    "    def __init__(self, maxpooling2d_module, kernel_size=3, stride=1, padding=0, qi=False, num_bits=None):\r\n",
    "        super(QMaxPooling2d, self).__init__(qi=qi, num_bits=num_bits)\r\n",
    "        self.maxpooling2d_module = maxpooling2d_module\r\n",
    "        self.kernel_size = kernel_size\r\n",
    "        self.stride = stride\r\n",
    "        self.padding = padding\r\n",
    "\r\n",
    "    def freeze(self, qi=None):\r\n",
    "        if hasattr(self, 'qi') and qi is not None:\r\n",
    "            raise ValueError('qi has been provided in init function.')\r\n",
    "        if not hasattr(self, 'qi') and qi is None:\r\n",
    "            raise ValueError('qi is not existed, should be provided.')\r\n",
    "        if qi is not None:\r\n",
    "            self.qi = qi\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        if hasattr(self, 'qi'):\r\n",
    "            self.qi.update(x)\r\n",
    "            x = self.qi.quantize_tensor(x)\r\n",
    "            x = self.qi.deuantize_tensor(x)\r\n",
    "\r\n",
    "        x = self.maxpooling2d_module(x)\r\n",
    "\r\n",
    "        return x\r\n",
    "    \r\n",
    "    def quantize_inference(self, x):\r\n",
    "        x = self.maxpooling2d_module(x.float()).int() # max_pool2d_with_indices_cpu\" not implemented for 'Int\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Complete QNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\r\n",
    "\r\n",
    "    def __init__(self, num_channels=1):\r\n",
    "        super(Net, self).__init__()\r\n",
    "        self.conv1 = nn.Conv2d(num_channels, 40, 3, 1)\r\n",
    "        self.conv2 = nn.Conv2d(40, 40, 3, 1,)\r\n",
    "        self.fc = nn.Linear(5*5*40, 10)\r\n",
    "        self.relu1 = nn.ReLU()\r\n",
    "        self.relu2 = nn.ReLU()\r\n",
    "        self.maxpool2d_1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\r\n",
    "        self.maxpool2d_2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.relu1(self.conv1(x))\r\n",
    "        x = self.maxpool2d_1(x)\r\n",
    "        x = self.relu2(self.conv2(x))\r\n",
    "        x = self.maxpool2d_2(x)\r\n",
    "        x = x.view(-1, 5*5*40)\r\n",
    "        x = self.fc(x)\r\n",
    "        return x\r\n",
    "    \r\n",
    "    def quantize(self, num_bits=8):\r\n",
    "        self.qconv1 = QConv2d(self.conv1,qi=True,qo=True,num_bits=num_bits)\r\n",
    "        self.qrelu1 = QReLU(self.relu1)\r\n",
    "        self.qmaxpool2d_1 = QMaxPooling2d(self.maxpool2d_1)\r\n",
    "        self.qconv2 = QConv2d(self.conv2,qi=False,qo=True,num_bits=num_bits)\r\n",
    "        self.qrelu2 = QReLU(self.relu2)\r\n",
    "        self.qmaxpool2d_2 = QMaxPooling2d(self.maxpool2d_2)\r\n",
    "        self.qfc = QLinear(self.fc,qi=False,qo=True,num_bits=num_bits)\r\n",
    "    \r\n",
    "    # forward and update QParams\r\n",
    "    def quantize_forward(self,x):\r\n",
    "        x = self.qrelu1(self.qconv1(x))\r\n",
    "        x = self.qmaxpool2d_1(x)\r\n",
    "        x = self.qrelu2(self.qconv2(x))\r\n",
    "        x = self.qmaxpool2d_2(x)\r\n",
    "        x = x.view(-1, 5*5*40)\r\n",
    "        x = self.qfc(x)\r\n",
    "        return x\r\n",
    "    \r\n",
    "    def freeze(self):\r\n",
    "        self.qconv1.freeze()\r\n",
    "        self.qrelu1.freeze(qi=self.qconv1.qo)\r\n",
    "        self.qmaxpool2d_1.freeze(qi=self.qconv1.qo)\r\n",
    "        self.qconv2.freeze(qi=self.qconv1.qo)\r\n",
    "        self.qrelu2.freeze(qi=self.qconv2.qo)\r\n",
    "        self.qmaxpool2d_2.freeze(qi=self.qconv2.qo)\r\n",
    "        self.qfc.freeze(qi=self.qconv2.qo)\r\n",
    "    \r\n",
    "    def quantize_inference(self, x):\r\n",
    "        # input should be quantized, and then all the calculations are performed on integer\r\n",
    "        qx = self.qconv1.qi.quantize_tensor(x)\r\n",
    "        print('qx dtype: ', qx.dtype) \r\n",
    "        qx = self.qconv1.quantize_inference(qx)\r\n",
    "        print('qx dtype: ', qx.dtype) \r\n",
    "        qx = self.qrelu1.quantize_inference(qx)\r\n",
    "        print('qx dtype: ', qx.dtype) \r\n",
    "        qx = self.qmaxpool2d_1.quantize_inference(qx)\r\n",
    "        print('qx dtype: ', qx.dtype) \r\n",
    "        qx = self.qconv2.quantize_inference(qx)\r\n",
    "        print('qx dtype: ', qx.dtype) \r\n",
    "        qx = self.qrelu2.quantize_inference(qx)\r\n",
    "        qx = self.qmaxpool2d_2.quantize_inference(qx)\r\n",
    "        qx = qx.view(-1, 5*5*40)\r\n",
    "        qx = self.qfc.quantize_inference(qx)\r\n",
    "        qx = self.qfc.qo.dequantize_tensor(qx)\r\n",
    "        return qx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\r\n",
    "    model.train()\r\n",
    "    lossLayer = torch.nn.CrossEntropyLoss()\r\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\r\n",
    "        data, target = data.to(device), target.to(device)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        output = model(data)\r\n",
    "        loss = lossLayer(output, target)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        if batch_idx % 50 == 0:\r\n",
    "            print('Train Epoch: {} [{}/{}]\\tLoss: {:.6f}'.format(\r\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset), loss.item()\r\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\r\n",
    "    model.eval()\r\n",
    "    test_loss = 0\r\n",
    "    correct = 0\r\n",
    "    lossLayer = torch.nn.CrossEntropyLoss(reduction='sum')\r\n",
    "    for data, target in test_loader:\r\n",
    "        data, target = data.to(device), target.to(device)\r\n",
    "        output = model(data)\r\n",
    "        test_loss += lossLayer(output, target).item()\r\n",
    "        pred = output.argmax(dim=1, keepdim=True)\r\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\r\n",
    "    \r\n",
    "    test_loss /= len(test_loader.dataset)\r\n",
    "\r\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {:.0f}%\\n'.format(\r\n",
    "        test_loss, 100. * correct / len(test_loader.dataset)\r\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_fashion_mnist(batch_size, resize=None):  #@save\r\n",
    "    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中。\"\"\"\r\n",
    "    trans = [transforms.ToTensor()]\r\n",
    "    if resize:\r\n",
    "        trans.insert(0, transforms.Resize(resize))\r\n",
    "    trans = transforms.Compose(trans)\r\n",
    "    mnist_train = datasets.FashionMNIST(root=\"../Data\",\r\n",
    "                                                    train=True,\r\n",
    "                                                    transform=trans,\r\n",
    "                                                    download=True)\r\n",
    "    mnist_test =  datasets.FashionMNIST(root=\"../Data\",\r\n",
    "                                                   train=False,\r\n",
    "                                                   transform=trans,\r\n",
    "                                                   download=True)\r\n",
    "    return (torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True,\r\n",
    "                            num_workers=4),\r\n",
    "            torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False,\r\n",
    "                            num_workers=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\r\n",
    "test_batch_size = 64\r\n",
    "seed = 1\r\n",
    "epochs = 15\r\n",
    "lr = 0.01\r\n",
    "momentum = 0.9\r\n",
    "save_model = True\r\n",
    "torch.manual_seed(seed) # fix the seed\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(num_channels=1)\r\n",
    "optimizer = optim.SGD(model.parameters(),lr=lr,momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000]\tLoss: 2.314084\n",
      "Train Epoch: 1 [3200/60000]\tLoss: 1.864382\n",
      "Train Epoch: 1 [6400/60000]\tLoss: 1.077437\n",
      "Train Epoch: 1 [9600/60000]\tLoss: 0.674443\n",
      "Train Epoch: 1 [12800/60000]\tLoss: 1.032035\n",
      "Train Epoch: 1 [16000/60000]\tLoss: 0.687428\n",
      "Train Epoch: 1 [19200/60000]\tLoss: 0.851558\n",
      "Train Epoch: 1 [22400/60000]\tLoss: 0.774539\n",
      "Train Epoch: 1 [25600/60000]\tLoss: 0.802545\n",
      "Train Epoch: 1 [28800/60000]\tLoss: 0.730229\n",
      "Train Epoch: 1 [32000/60000]\tLoss: 0.795217\n",
      "Train Epoch: 1 [35200/60000]\tLoss: 0.853380\n",
      "Train Epoch: 1 [38400/60000]\tLoss: 0.704790\n",
      "Train Epoch: 1 [41600/60000]\tLoss: 0.655076\n",
      "Train Epoch: 1 [44800/60000]\tLoss: 0.727883\n",
      "Train Epoch: 1 [48000/60000]\tLoss: 0.612061\n",
      "Train Epoch: 1 [51200/60000]\tLoss: 0.579158\n",
      "Train Epoch: 1 [54400/60000]\tLoss: 0.561521\n",
      "Train Epoch: 1 [57600/60000]\tLoss: 0.893712\n",
      "\n",
      "Test set: Average loss: 0.6126, Accuracy: 78%\n",
      "\n",
      "Train Epoch: 2 [0/60000]\tLoss: 0.524307\n",
      "Train Epoch: 2 [3200/60000]\tLoss: 0.446216\n",
      "Train Epoch: 2 [6400/60000]\tLoss: 0.663923\n",
      "Train Epoch: 2 [9600/60000]\tLoss: 0.490333\n",
      "Train Epoch: 2 [12800/60000]\tLoss: 0.609139\n",
      "Train Epoch: 2 [16000/60000]\tLoss: 0.625907\n",
      "Train Epoch: 2 [19200/60000]\tLoss: 0.604615\n",
      "Train Epoch: 2 [22400/60000]\tLoss: 0.680532\n",
      "Train Epoch: 2 [25600/60000]\tLoss: 0.571551\n",
      "Train Epoch: 2 [28800/60000]\tLoss: 0.430085\n",
      "Train Epoch: 2 [32000/60000]\tLoss: 0.534035\n",
      "Train Epoch: 2 [35200/60000]\tLoss: 0.488387\n",
      "Train Epoch: 2 [38400/60000]\tLoss: 0.496292\n",
      "Train Epoch: 2 [41600/60000]\tLoss: 0.326326\n",
      "Train Epoch: 2 [44800/60000]\tLoss: 0.679052\n",
      "Train Epoch: 2 [48000/60000]\tLoss: 0.460204\n",
      "Train Epoch: 2 [51200/60000]\tLoss: 0.529561\n",
      "Train Epoch: 2 [54400/60000]\tLoss: 0.625051\n",
      "Train Epoch: 2 [57600/60000]\tLoss: 0.434773\n",
      "\n",
      "Test set: Average loss: 0.5031, Accuracy: 82%\n",
      "\n",
      "Train Epoch: 3 [0/60000]\tLoss: 0.370661\n",
      "Train Epoch: 3 [3200/60000]\tLoss: 0.507737\n",
      "Train Epoch: 3 [6400/60000]\tLoss: 0.629790\n",
      "Train Epoch: 3 [9600/60000]\tLoss: 0.272545\n",
      "Train Epoch: 3 [12800/60000]\tLoss: 0.388173\n",
      "Train Epoch: 3 [16000/60000]\tLoss: 0.602174\n",
      "Train Epoch: 3 [19200/60000]\tLoss: 0.567635\n",
      "Train Epoch: 3 [22400/60000]\tLoss: 0.258308\n",
      "Train Epoch: 3 [25600/60000]\tLoss: 0.384268\n",
      "Train Epoch: 3 [28800/60000]\tLoss: 0.421351\n",
      "Train Epoch: 3 [32000/60000]\tLoss: 0.631595\n",
      "Train Epoch: 3 [35200/60000]\tLoss: 0.302390\n",
      "Train Epoch: 3 [38400/60000]\tLoss: 0.392634\n",
      "Train Epoch: 3 [41600/60000]\tLoss: 0.548646\n",
      "Train Epoch: 3 [44800/60000]\tLoss: 0.512104\n",
      "Train Epoch: 3 [48000/60000]\tLoss: 0.449967\n",
      "Train Epoch: 3 [51200/60000]\tLoss: 0.558844\n",
      "Train Epoch: 3 [54400/60000]\tLoss: 0.290831\n",
      "Train Epoch: 3 [57600/60000]\tLoss: 0.300253\n",
      "\n",
      "Test set: Average loss: 0.4951, Accuracy: 82%\n",
      "\n",
      "Train Epoch: 4 [0/60000]\tLoss: 0.534201\n",
      "Train Epoch: 4 [3200/60000]\tLoss: 0.379022\n",
      "Train Epoch: 4 [6400/60000]\tLoss: 0.627194\n",
      "Train Epoch: 4 [9600/60000]\tLoss: 0.482313\n",
      "Train Epoch: 4 [12800/60000]\tLoss: 0.428766\n",
      "Train Epoch: 4 [16000/60000]\tLoss: 0.438794\n",
      "Train Epoch: 4 [19200/60000]\tLoss: 0.502944\n",
      "Train Epoch: 4 [22400/60000]\tLoss: 0.626282\n",
      "Train Epoch: 4 [25600/60000]\tLoss: 0.490108\n",
      "Train Epoch: 4 [28800/60000]\tLoss: 0.511524\n",
      "Train Epoch: 4 [32000/60000]\tLoss: 0.444510\n",
      "Train Epoch: 4 [35200/60000]\tLoss: 0.212190\n",
      "Train Epoch: 4 [38400/60000]\tLoss: 0.407776\n",
      "Train Epoch: 4 [41600/60000]\tLoss: 0.393969\n",
      "Train Epoch: 4 [44800/60000]\tLoss: 0.350789\n",
      "Train Epoch: 4 [48000/60000]\tLoss: 0.627055\n",
      "Train Epoch: 4 [51200/60000]\tLoss: 0.307794\n",
      "Train Epoch: 4 [54400/60000]\tLoss: 0.549585\n",
      "Train Epoch: 4 [57600/60000]\tLoss: 0.406413\n",
      "\n",
      "Test set: Average loss: 0.4253, Accuracy: 85%\n",
      "\n",
      "Train Epoch: 5 [0/60000]\tLoss: 0.285875\n",
      "Train Epoch: 5 [3200/60000]\tLoss: 0.429464\n",
      "Train Epoch: 5 [6400/60000]\tLoss: 0.335358\n",
      "Train Epoch: 5 [9600/60000]\tLoss: 0.345472\n",
      "Train Epoch: 5 [12800/60000]\tLoss: 0.372791\n",
      "Train Epoch: 5 [16000/60000]\tLoss: 0.616034\n",
      "Train Epoch: 5 [19200/60000]\tLoss: 0.354180\n",
      "Train Epoch: 5 [22400/60000]\tLoss: 0.550242\n",
      "Train Epoch: 5 [25600/60000]\tLoss: 0.326668\n",
      "Train Epoch: 5 [28800/60000]\tLoss: 0.286878\n",
      "Train Epoch: 5 [32000/60000]\tLoss: 0.306904\n",
      "Train Epoch: 5 [35200/60000]\tLoss: 0.456002\n",
      "Train Epoch: 5 [38400/60000]\tLoss: 0.460792\n",
      "Train Epoch: 5 [41600/60000]\tLoss: 0.172339\n",
      "Train Epoch: 5 [44800/60000]\tLoss: 0.271411\n",
      "Train Epoch: 5 [48000/60000]\tLoss: 0.443100\n",
      "Train Epoch: 5 [51200/60000]\tLoss: 0.363883\n",
      "Train Epoch: 5 [54400/60000]\tLoss: 0.343888\n",
      "Train Epoch: 5 [57600/60000]\tLoss: 0.565937\n",
      "\n",
      "Test set: Average loss: 0.4147, Accuracy: 85%\n",
      "\n",
      "Train Epoch: 6 [0/60000]\tLoss: 0.334031\n",
      "Train Epoch: 6 [3200/60000]\tLoss: 0.325441\n",
      "Train Epoch: 6 [6400/60000]\tLoss: 0.403338\n",
      "Train Epoch: 6 [9600/60000]\tLoss: 0.281545\n",
      "Train Epoch: 6 [12800/60000]\tLoss: 0.442509\n",
      "Train Epoch: 6 [16000/60000]\tLoss: 0.515603\n",
      "Train Epoch: 6 [19200/60000]\tLoss: 0.465191\n",
      "Train Epoch: 6 [22400/60000]\tLoss: 0.308574\n",
      "Train Epoch: 6 [25600/60000]\tLoss: 0.520156\n",
      "Train Epoch: 6 [28800/60000]\tLoss: 0.391832\n",
      "Train Epoch: 6 [32000/60000]\tLoss: 0.507426\n",
      "Train Epoch: 6 [35200/60000]\tLoss: 0.590668\n",
      "Train Epoch: 6 [38400/60000]\tLoss: 0.475004\n",
      "Train Epoch: 6 [41600/60000]\tLoss: 0.337259\n",
      "Train Epoch: 6 [44800/60000]\tLoss: 0.542211\n",
      "Train Epoch: 6 [48000/60000]\tLoss: 0.432346\n",
      "Train Epoch: 6 [51200/60000]\tLoss: 0.509786\n",
      "Train Epoch: 6 [54400/60000]\tLoss: 0.403243\n",
      "Train Epoch: 6 [57600/60000]\tLoss: 0.625143\n",
      "\n",
      "Test set: Average loss: 0.3955, Accuracy: 86%\n",
      "\n",
      "Train Epoch: 7 [0/60000]\tLoss: 0.368778\n",
      "Train Epoch: 7 [3200/60000]\tLoss: 0.260464\n",
      "Train Epoch: 7 [6400/60000]\tLoss: 0.462144\n",
      "Train Epoch: 7 [9600/60000]\tLoss: 0.391225\n",
      "Train Epoch: 7 [12800/60000]\tLoss: 0.321869\n",
      "Train Epoch: 7 [16000/60000]\tLoss: 0.262131\n",
      "Train Epoch: 7 [19200/60000]\tLoss: 0.205683\n",
      "Train Epoch: 7 [22400/60000]\tLoss: 0.431829\n",
      "Train Epoch: 7 [25600/60000]\tLoss: 0.557534\n",
      "Train Epoch: 7 [28800/60000]\tLoss: 0.367404\n",
      "Train Epoch: 7 [32000/60000]\tLoss: 0.369738\n",
      "Train Epoch: 7 [35200/60000]\tLoss: 0.436471\n",
      "Train Epoch: 7 [38400/60000]\tLoss: 0.439639\n",
      "Train Epoch: 7 [41600/60000]\tLoss: 0.375890\n",
      "Train Epoch: 7 [44800/60000]\tLoss: 0.458373\n",
      "Train Epoch: 7 [48000/60000]\tLoss: 0.553217\n",
      "Train Epoch: 7 [51200/60000]\tLoss: 0.377482\n",
      "Train Epoch: 7 [54400/60000]\tLoss: 0.417634\n",
      "Train Epoch: 7 [57600/60000]\tLoss: 0.352851\n",
      "\n",
      "Test set: Average loss: 0.4056, Accuracy: 86%\n",
      "\n",
      "Train Epoch: 8 [0/60000]\tLoss: 0.285126\n",
      "Train Epoch: 8 [3200/60000]\tLoss: 0.380628\n",
      "Train Epoch: 8 [6400/60000]\tLoss: 0.414230\n",
      "Train Epoch: 8 [9600/60000]\tLoss: 0.317395\n",
      "Train Epoch: 8 [12800/60000]\tLoss: 0.360131\n",
      "Train Epoch: 8 [16000/60000]\tLoss: 0.356607\n",
      "Train Epoch: 8 [19200/60000]\tLoss: 0.293103\n",
      "Train Epoch: 8 [22400/60000]\tLoss: 0.379725\n",
      "Train Epoch: 8 [25600/60000]\tLoss: 0.300234\n",
      "Train Epoch: 8 [28800/60000]\tLoss: 0.481668\n",
      "Train Epoch: 8 [32000/60000]\tLoss: 0.571478\n",
      "Train Epoch: 8 [35200/60000]\tLoss: 0.231610\n",
      "Train Epoch: 8 [38400/60000]\tLoss: 0.383229\n",
      "Train Epoch: 8 [41600/60000]\tLoss: 0.312017\n",
      "Train Epoch: 8 [44800/60000]\tLoss: 0.178635\n",
      "Train Epoch: 8 [48000/60000]\tLoss: 0.457991\n",
      "Train Epoch: 8 [51200/60000]\tLoss: 0.367215\n",
      "Train Epoch: 8 [54400/60000]\tLoss: 0.307652\n",
      "Train Epoch: 8 [57600/60000]\tLoss: 0.294281\n",
      "\n",
      "Test set: Average loss: 0.3833, Accuracy: 86%\n",
      "\n",
      "Train Epoch: 9 [0/60000]\tLoss: 0.280571\n",
      "Train Epoch: 9 [3200/60000]\tLoss: 0.370082\n",
      "Train Epoch: 9 [6400/60000]\tLoss: 0.264888\n",
      "Train Epoch: 9 [9600/60000]\tLoss: 0.222248\n",
      "Train Epoch: 9 [12800/60000]\tLoss: 0.310383\n",
      "Train Epoch: 9 [16000/60000]\tLoss: 0.442237\n",
      "Train Epoch: 9 [19200/60000]\tLoss: 0.246919\n",
      "Train Epoch: 9 [22400/60000]\tLoss: 0.344476\n",
      "Train Epoch: 9 [25600/60000]\tLoss: 0.244344\n",
      "Train Epoch: 9 [28800/60000]\tLoss: 0.269025\n",
      "Train Epoch: 9 [32000/60000]\tLoss: 0.284660\n",
      "Train Epoch: 9 [35200/60000]\tLoss: 0.395749\n",
      "Train Epoch: 9 [38400/60000]\tLoss: 0.275959\n",
      "Train Epoch: 9 [41600/60000]\tLoss: 0.330300\n",
      "Train Epoch: 9 [44800/60000]\tLoss: 0.384020\n",
      "Train Epoch: 9 [48000/60000]\tLoss: 0.456565\n",
      "Train Epoch: 9 [51200/60000]\tLoss: 0.344506\n",
      "Train Epoch: 9 [54400/60000]\tLoss: 0.210120\n",
      "Train Epoch: 9 [57600/60000]\tLoss: 0.426503\n",
      "\n",
      "Test set: Average loss: 0.3637, Accuracy: 87%\n",
      "\n",
      "Train Epoch: 10 [0/60000]\tLoss: 0.384219\n",
      "Train Epoch: 10 [3200/60000]\tLoss: 0.372955\n",
      "Train Epoch: 10 [6400/60000]\tLoss: 0.296669\n",
      "Train Epoch: 10 [9600/60000]\tLoss: 0.254765\n",
      "Train Epoch: 10 [12800/60000]\tLoss: 0.274546\n",
      "Train Epoch: 10 [16000/60000]\tLoss: 0.471415\n",
      "Train Epoch: 10 [19200/60000]\tLoss: 0.546347\n",
      "Train Epoch: 10 [22400/60000]\tLoss: 0.322773\n",
      "Train Epoch: 10 [25600/60000]\tLoss: 0.272665\n",
      "Train Epoch: 10 [28800/60000]\tLoss: 0.371797\n",
      "Train Epoch: 10 [32000/60000]\tLoss: 0.364258\n",
      "Train Epoch: 10 [35200/60000]\tLoss: 0.495544\n",
      "Train Epoch: 10 [38400/60000]\tLoss: 0.288989\n",
      "Train Epoch: 10 [41600/60000]\tLoss: 0.385890\n",
      "Train Epoch: 10 [44800/60000]\tLoss: 0.235527\n",
      "Train Epoch: 10 [48000/60000]\tLoss: 0.375797\n",
      "Train Epoch: 10 [51200/60000]\tLoss: 0.249705\n",
      "Train Epoch: 10 [54400/60000]\tLoss: 0.428846\n",
      "Train Epoch: 10 [57600/60000]\tLoss: 0.220053\n",
      "\n",
      "Test set: Average loss: 0.3599, Accuracy: 87%\n",
      "\n",
      "Train Epoch: 11 [0/60000]\tLoss: 0.281599\n",
      "Train Epoch: 11 [3200/60000]\tLoss: 0.220964\n",
      "Train Epoch: 11 [6400/60000]\tLoss: 0.236762\n",
      "Train Epoch: 11 [9600/60000]\tLoss: 0.204255\n",
      "Train Epoch: 11 [12800/60000]\tLoss: 0.421699\n",
      "Train Epoch: 11 [16000/60000]\tLoss: 0.285321\n",
      "Train Epoch: 11 [19200/60000]\tLoss: 0.278064\n",
      "Train Epoch: 11 [22400/60000]\tLoss: 0.401666\n",
      "Train Epoch: 11 [25600/60000]\tLoss: 0.445721\n",
      "Train Epoch: 11 [28800/60000]\tLoss: 0.316532\n",
      "Train Epoch: 11 [32000/60000]\tLoss: 0.218847\n",
      "Train Epoch: 11 [35200/60000]\tLoss: 0.332498\n",
      "Train Epoch: 11 [38400/60000]\tLoss: 0.421374\n",
      "Train Epoch: 11 [41600/60000]\tLoss: 0.268290\n",
      "Train Epoch: 11 [44800/60000]\tLoss: 0.181045\n",
      "Train Epoch: 11 [48000/60000]\tLoss: 0.395020\n",
      "Train Epoch: 11 [51200/60000]\tLoss: 0.451698\n",
      "Train Epoch: 11 [54400/60000]\tLoss: 0.207593\n",
      "Train Epoch: 11 [57600/60000]\tLoss: 0.284179\n",
      "\n",
      "Test set: Average loss: 0.3500, Accuracy: 88%\n",
      "\n",
      "Train Epoch: 12 [0/60000]\tLoss: 0.201473\n",
      "Train Epoch: 12 [3200/60000]\tLoss: 0.336593\n",
      "Train Epoch: 12 [6400/60000]\tLoss: 0.433342\n",
      "Train Epoch: 12 [9600/60000]\tLoss: 0.178104\n",
      "Train Epoch: 12 [12800/60000]\tLoss: 0.500753\n",
      "Train Epoch: 12 [16000/60000]\tLoss: 0.334958\n",
      "Train Epoch: 12 [19200/60000]\tLoss: 0.353154\n",
      "Train Epoch: 12 [22400/60000]\tLoss: 0.298424\n",
      "Train Epoch: 12 [25600/60000]\tLoss: 0.354083\n",
      "Train Epoch: 12 [28800/60000]\tLoss: 0.308105\n",
      "Train Epoch: 12 [32000/60000]\tLoss: 0.481337\n",
      "Train Epoch: 12 [35200/60000]\tLoss: 0.332375\n",
      "Train Epoch: 12 [38400/60000]\tLoss: 0.244090\n",
      "Train Epoch: 12 [41600/60000]\tLoss: 0.404490\n",
      "Train Epoch: 12 [44800/60000]\tLoss: 0.172966\n",
      "Train Epoch: 12 [48000/60000]\tLoss: 0.253951\n",
      "Train Epoch: 12 [51200/60000]\tLoss: 0.410159\n",
      "Train Epoch: 12 [54400/60000]\tLoss: 0.346277\n",
      "Train Epoch: 12 [57600/60000]\tLoss: 0.341938\n",
      "\n",
      "Test set: Average loss: 0.3533, Accuracy: 87%\n",
      "\n",
      "Train Epoch: 13 [0/60000]\tLoss: 0.324862\n",
      "Train Epoch: 13 [3200/60000]\tLoss: 0.414775\n",
      "Train Epoch: 13 [6400/60000]\tLoss: 0.295399\n",
      "Train Epoch: 13 [9600/60000]\tLoss: 0.210751\n",
      "Train Epoch: 13 [12800/60000]\tLoss: 0.284058\n",
      "Train Epoch: 13 [16000/60000]\tLoss: 0.272443\n",
      "Train Epoch: 13 [19200/60000]\tLoss: 0.254123\n",
      "Train Epoch: 13 [22400/60000]\tLoss: 0.244969\n",
      "Train Epoch: 13 [25600/60000]\tLoss: 0.325918\n",
      "Train Epoch: 13 [28800/60000]\tLoss: 0.346443\n",
      "Train Epoch: 13 [32000/60000]\tLoss: 0.332977\n",
      "Train Epoch: 13 [35200/60000]\tLoss: 0.293576\n",
      "Train Epoch: 13 [38400/60000]\tLoss: 0.211647\n",
      "Train Epoch: 13 [41600/60000]\tLoss: 0.390077\n",
      "Train Epoch: 13 [44800/60000]\tLoss: 0.137061\n",
      "Train Epoch: 13 [48000/60000]\tLoss: 0.346676\n",
      "Train Epoch: 13 [51200/60000]\tLoss: 0.351605\n",
      "Train Epoch: 13 [54400/60000]\tLoss: 0.323326\n",
      "Train Epoch: 13 [57600/60000]\tLoss: 0.377090\n",
      "\n",
      "Test set: Average loss: 0.3459, Accuracy: 88%\n",
      "\n",
      "Train Epoch: 14 [0/60000]\tLoss: 0.286164\n",
      "Train Epoch: 14 [3200/60000]\tLoss: 0.259584\n",
      "Train Epoch: 14 [6400/60000]\tLoss: 0.363681\n",
      "Train Epoch: 14 [9600/60000]\tLoss: 0.299349\n",
      "Train Epoch: 14 [12800/60000]\tLoss: 0.263174\n",
      "Train Epoch: 14 [16000/60000]\tLoss: 0.251494\n",
      "Train Epoch: 14 [19200/60000]\tLoss: 0.221192\n",
      "Train Epoch: 14 [22400/60000]\tLoss: 0.289089\n",
      "Train Epoch: 14 [25600/60000]\tLoss: 0.217701\n",
      "Train Epoch: 14 [28800/60000]\tLoss: 0.219189\n",
      "Train Epoch: 14 [32000/60000]\tLoss: 0.278214\n",
      "Train Epoch: 14 [35200/60000]\tLoss: 0.417530\n",
      "Train Epoch: 14 [38400/60000]\tLoss: 0.216490\n",
      "Train Epoch: 14 [41600/60000]\tLoss: 0.332930\n",
      "Train Epoch: 14 [44800/60000]\tLoss: 0.395848\n",
      "Train Epoch: 14 [48000/60000]\tLoss: 0.198318\n",
      "Train Epoch: 14 [51200/60000]\tLoss: 0.364075\n",
      "Train Epoch: 14 [54400/60000]\tLoss: 0.374476\n",
      "Train Epoch: 14 [57600/60000]\tLoss: 0.163042\n",
      "\n",
      "Test set: Average loss: 0.3332, Accuracy: 88%\n",
      "\n",
      "Train Epoch: 15 [0/60000]\tLoss: 0.338857\n",
      "Train Epoch: 15 [3200/60000]\tLoss: 0.305462\n",
      "Train Epoch: 15 [6400/60000]\tLoss: 0.324018\n",
      "Train Epoch: 15 [9600/60000]\tLoss: 0.313183\n",
      "Train Epoch: 15 [12800/60000]\tLoss: 0.403538\n",
      "Train Epoch: 15 [16000/60000]\tLoss: 0.262503\n",
      "Train Epoch: 15 [19200/60000]\tLoss: 0.262689\n",
      "Train Epoch: 15 [22400/60000]\tLoss: 0.299977\n",
      "Train Epoch: 15 [25600/60000]\tLoss: 0.244138\n",
      "Train Epoch: 15 [28800/60000]\tLoss: 0.416960\n",
      "Train Epoch: 15 [32000/60000]\tLoss: 0.379064\n",
      "Train Epoch: 15 [35200/60000]\tLoss: 0.521464\n",
      "Train Epoch: 15 [38400/60000]\tLoss: 0.186500\n",
      "Train Epoch: 15 [41600/60000]\tLoss: 0.222349\n",
      "Train Epoch: 15 [44800/60000]\tLoss: 0.533961\n",
      "Train Epoch: 15 [48000/60000]\tLoss: 0.329116\n",
      "Train Epoch: 15 [51200/60000]\tLoss: 0.316132\n",
      "Train Epoch: 15 [54400/60000]\tLoss: 0.381197\n",
      "Train Epoch: 15 [57600/60000]\tLoss: 0.155975\n",
      "\n",
      "Test set: Average loss: 0.3367, Accuracy: 88%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\r\n",
    "        train(model, device, train_iter, optimizer, epoch)\r\n",
    "        test(model, device, test_iter)\r\n",
    "if save_model:\r\n",
    "    if not os.path.exists('ckpt'):\r\n",
    "        os.makedirs('ckpt')\r\n",
    "    torch.save(model.state_dict(), 'ckpt/mnist_cnn.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Post Training Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_quantize(model, test_loader):\r\n",
    "    for i, (data, target) in enumerate(test_loader, 1):\r\n",
    "        output = model.quantize_forward(data)\r\n",
    "        if i % 200 == 0:\r\n",
    "            break\r\n",
    "    print('direct quantization finish')\r\n",
    "\r\n",
    "def quantize_inference(model, test_loader):\r\n",
    "    correct = 0\r\n",
    "    for i, (data, target) in enumerate(test_loader, 1):\r\n",
    "        output = model.quantize_inference(data)\r\n",
    "        pred = output.argmax(dim=1, keepdim=True)\r\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\r\n",
    "    print('\\nTest set: Quant Model Accuracy: {:.0f}%\\n'.format(100. * correct / len(test_loader.dataset)))\r\n",
    "\r\n",
    "def full_inference(model, test_loader):\r\n",
    "    correct = 0\r\n",
    "    for i, (data, target) in enumerate(test_loader, 1):\r\n",
    "        output = model(data)\r\n",
    "        pred = output.argmax(dim=1, keepdim=True)\r\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\r\n",
    "    print('\\nTest set: Full Model Accuracy: {:.0f}%\\n'.format(100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\r\n",
    "model.load_state_dict(torch.load('./ckpt/mnist_cnn.pt'))\r\n",
    "model.quantize(num_bits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Full Model Accuracy: 88%\n",
      "\n",
      "runtime:  4.376999616622925\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\r\n",
    "full_inference(model,test_iter)\r\n",
    "end = time.time()\r\n",
    "print('runtime: ', end- begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "direct quantization finish\n"
     ]
    }
   ],
   "source": [
    "direct_quantize(model,train_iter) # statistics the value of rmin rmax and updates scale zero_point\r\n",
    "model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int8"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.qconv1.conv_module.bias.data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qx dtype:  torch.uint8\n",
      "qx dtype:  torch.int32\n",
      "qx dtype:  torch.int32\n",
      "qx dtype:  torch.int32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Int but found Byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-213-8ef40918482a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbegin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mquantize_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'runtime: '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-165-2e9275338b44>\u001b[0m in \u001b[0;36mquantize_inference\u001b[1;34m(model, test_loader)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantize_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-209-2636ee97bbd5>\u001b[0m in \u001b[0;36mquantize_inference\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mqx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqmaxpool2d_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantize_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'qx dtype: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0mqx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqconv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantize_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'qx dtype: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mqx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqrelu2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantize_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-202-e4e676aa7070>\u001b[0m in \u001b[0;36mquantize_inference\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_point\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# calculate in 8 bits integer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mM\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# self.M is still in float format, need to be concert to int\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_point\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 419\u001b[1;33m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[0;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Int but found Byte"
     ]
    }
   ],
   "source": [
    "begin = time.time()\r\n",
    "with torch.no_grad():\r\n",
    "    quantize_inference(model,test_iter)\r\n",
    "end = time.time()\r\n",
    "print('runtime: ',end-begin)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2da3054de1e1f92a7020da7fcce7561bffae4c7465d8b7b96a49007e7eb1b1f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}